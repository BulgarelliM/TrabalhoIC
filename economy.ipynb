{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ['./dados/']\n",
    "filepath = os.sep.join(data_path + ['economy.csv'])\n",
    "data = pd.read_csv(filepath, sep=',')\n",
    "data_orig = data.copy()\n",
    "data2 = data.copy()\n",
    "\n",
    "filepath = os.sep.join(data_path + ['results.csv'])\n",
    "results = pd.read_csv(filepath, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_match_winer(match_id):\n",
    "    row = results.loc[results['match_id'] == match_id]\n",
    "    return row.head(1)['match_winner']\n",
    "\n",
    "winner =[]\n",
    "for i,row in data.iterrows():\n",
    "    match_winner = search_match_winer(row['match_id'])\n",
    "    winner.append(match_winner.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_pd= []\n",
    "for win in winner:\n",
    "    if win:\n",
    "        winner_pd.append(win[0])\n",
    "    else: \n",
    "        winner_pd.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data['match_winner'] = pd.DataFrame(winner_pd)\n",
    "print(data.shape)\n",
    "data.dropna(subset=['match_winner'],inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['date'], axis=1)\n",
    "data = data.drop(['match_id'], axis=1)\n",
    "data = data.drop(['event_id'], axis=1)\n",
    "data = data.drop(['best_of'], axis=1)\n",
    "data = data.drop(['team_1'], axis=1)\n",
    "data = data.drop(['team_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data.replace(np.nan,0)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = data.hist(figsize = (20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncoding(df, column):\n",
    "    one_hot_encoded = pd.get_dummies(df[column])\n",
    "    df = df.drop(column,axis = 1)\n",
    "    df = df.join(one_hot_encoded)\n",
    "    return df\n",
    "\n",
    "data_aux = {}\n",
    "pd.DataFrame(data_aux)\n",
    "categorical_features = ['_map'] # ['_map', 'team_1', 'team_2']\n",
    "for i in categorical_features:\n",
    "    data_aux = oneHotEncoding(data, i)\n",
    "    data= data_aux.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## estamos subistiuindo para inteiros onde t = o e ct =1 \n",
    "data['t1_start'] = data['t1_start'].replace('t',0)\n",
    "data['t1_start'] = data['t1_start'].replace('ct',1)\n",
    "data['t2_start'] = data['t2_start'].replace('t',0)\n",
    "data['t2_start'] = data['t2_start'].replace('ct',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    data[col] = data[col].astype(np.float)\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "data = data.reset_index(drop=True)\n",
    "X = data.drop('match_winner', axis=1)\n",
    "y = data.match_winner\n",
    "sss = StratifiedShuffleSplit(n_splits=10, random_state=50)\n",
    "\n",
    "def get_avg_score(n):\n",
    "    pipe = [\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('pca', PCA(n_components=n)),\n",
    "        ('estimator', LogisticRegression(max_iter=1000))\n",
    "    ]\n",
    "    pipe = Pipeline(pipe)\n",
    "    scores = []\n",
    "    \n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        pipe.fit(X_train, y_train)\n",
    "        scores.append(accuracy_score(y_test, pipe.predict(X_test)))\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ns = np.arange(1,103)\n",
    "score_list = [get_avg_score(n) for n in ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "ax = plt.axes()\n",
    "ax.plot(ns, score_list)\n",
    "ax.set(xlabel='Number of Dimensions',\n",
    "       ylabel='Average Accuracy',\n",
    "       title='LogisticRegression ACC vs Number of dimensions')\n",
    "ax.grid(True)\n",
    "plt.savefig(f'StandardScaler.png', dpi=100)\n",
    "print(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.5472423573904821, 0.7055783170501103, 0.7073747242357389, 0.710463283958399, 0.7267254963756697, 0.7323983611723921, 0.7370942325874568, 0.7379136463914276, 0.7387015442798612, 0.7398046013236684, 0.7417901040025212, 0.7521273242987708, 0.7520327765521589, 0.7520012606366214, 0.7511818468326505, 0.7515915537346359, 0.7522533879609202, 0.7579892845887172, 0.7582098959974788, 0.7598487236054208, 0.7587141506460762, 0.7606051055783171, 0.7624330286794831, 0.7620863536085725, 0.7745351402458241, 0.7958398991490704, 0.7958714150646076, 0.7965647652064293, 0.796816892530728, 0.7971005357705641, 0.7976678222502364, 0.7991805861960289, 0.8078789788843365, 0.8098959974787266, 0.8098014497321147, 0.8091396155058306, 0.8105263157894738, 0.809643870154428, 0.8100850929719507, 0.8092026473369052, 0.8096753860699654, 0.8107469271982352, 0.8107784431137723, 0.8122281752284903, 0.8125748502994012, 0.8124172707217145, 0.8126693980460132, 0.814276709738418, 0.8155058304443745, 0.8153167349511502, 0.8162937283328082, 0.8154743145288371, 0.8161046328395839, 0.8160416010085093, 0.8165773715726441, 0.8167034352347935, 0.8172392057989285, 0.8174913331232272, 0.817018594390167, 0.8176804286164513, 0.8173022376300032, 0.8203277655215884, 0.820201701859439, 0.820737472423574, 0.8209265679167979, 0.8213047589032462, 0.8210841474944847, 0.8219035612984558, 0.8224393318625906, 0.8225023636936653, 0.8220926567916799, 0.8224393318625906, 0.8229751024267256, 0.8233217774976364, 0.823573904821935, 0.8250866687677277, 0.8265048849669082, 0.8258745666561614, 0.8287109990545225, 0.829026158209896, 0.8295934446895682, 0.8294358651118815, 0.8288685786322093, 0.8299401197604791, 0.8299716356760163, 0.8304128584935393, 0.8313268200441224, 0.8316419791994958, 0.8314213677907343, 0.8380081941380398, 0.8383548692089505, 0.8381657737157264, 0.838575480617712, 0.8382603214623383, 0.838670028364324, 0.8385439647021746, 0.838670028364324, 0.838670028364324, 0.8386385124487866, 0.838575480617712, 0.838575480617712, 0.838575480617712]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
